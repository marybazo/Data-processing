{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install translator for catalog\n",
    "%pip install googletrans==4.0.0-rc1\n",
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from googletrans import Translator\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "root = 'archive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "### <a href='https://www.kaggle.com/datasets/svizor/retail-sales-forecasting-data'> Retail sales forcastiong data</a></br>\n",
    "This dataset contains sales information from four stores of one of the retailers over 25 months. </br>\n",
    "Participants are expected to use these files to develop models that can predict customer demand. </br>\n",
    "Additionally, the dataset includes a holdout sample with sales data for a 1-month period for which </br>\n",
    "forecasts should be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What will be done with data\n",
    "1.\tCreate English names for products. (long process, data store in final_catalog.csv)\n",
    "2.\tCreate synthetic clients, employees, and orders.\n",
    "3.\tRead online sales data and add all dimensions to it.\n",
    "4.\tRead offline data and reduce it from 7.5 million to 1.5 million records.\n",
    "5.\tAdd all necessary dimensions to offline sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Reading down in code !\n",
    "\n",
    "# sales  = pd.read_csv(root + 'sales.csv', index_col=0)\n",
    "# online  = pd.read_csv(root + 'online.csv', index_col=0)\n",
    "\n",
    "# catalog = pd.read_csv(root + 'catalog.csv', index_col=0)\n",
    "# stores  = pd.read_csv(root + 'stores.csv', index_col=0)\n",
    "\n",
    "# price_history  = pd.read_csv(root + 'price_history.csv', index_col=0)\n",
    "\n",
    "# actual_matrix  = pd.read_csv(root + 'actual_matrix.csv', index_col=0)\n",
    "# discounts_history  = pd.read_csv(root + 'discounts_history.csv', index_col=0)\n",
    "# markdowns  = pd.read_csv(root + 'markdowns.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## catalog.csv\n",
    "Purpose: Product catalog with characteristics.</br>\n",
    "Columns:</br>\n",
    "item_id: A unique identifier for each product</br>\n",
    "dept_name: Product department (hierarchy level)</br>\n",
    "class_name: Product class (hierarchy level)</br>\n",
    "subclass_name: Product subclass (hierarchy level)</br>\n",
    "item_type: Product type</br>\n",
    "weight_volume: Volumetric weight</br>\n",
    "weight_netto: Net weight</br>\n",
    "fatness: Fat content</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>subclass_name</th>\n",
       "      <th>item_type</th>\n",
       "      <th>weight_volume</th>\n",
       "      <th>weight_netto</th>\n",
       "      <th>fatness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da17e2d5feda</td>\n",
       "      <td>БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>БУМАЖНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВЛАЖНЫЕ САЛФЕТКИ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>614de2b96018</td>\n",
       "      <td>БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВАТНЫЕ ДИСКИ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c1f1f3e3e11</td>\n",
       "      <td>БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВАТНЫЕ ДИСКИ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                 dept_name          class_name  \\\n",
       "0  da17e2d5feda  БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ  БУМАЖНАЯ ПРОДУКЦИЯ   \n",
       "1  614de2b96018  БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ    ВАТНАЯ ПРОДУКЦИЯ   \n",
       "2  0c1f1f3e3e11  БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ    ВАТНАЯ ПРОДУКЦИЯ   \n",
       "\n",
       "      subclass_name item_type  weight_volume  weight_netto  fatness  \n",
       "0  ВЛАЖНЫЕ САЛФЕТКИ       NaN          150.0           NaN      NaN  \n",
       "1      ВАТНЫЕ ДИСКИ       NaN           30.0           NaN      NaN  \n",
       "2      ВАТНЫЕ ДИСКИ       NaN            NaN           NaN      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog = pd.read_csv(root + 'catalog.csv', index_col=0)\n",
    "catalog.head(3) # TRANSLATE dept_name class_name subclass_name item_type into ENGLISH, and add to catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process batches to translate\n",
    "def batch_translate(items, batch_size, pause_seconds):\n",
    "    # create df for translation\n",
    "    translator = Translator()\n",
    "    names_translated = pd.DataFrame(columns=['name_ru', 'name_en'])\n",
    "\n",
    "    for i in range(0, len(items), batch_size):\n",
    "        batch = items[i:i+batch_size]\n",
    "        \n",
    "        # Translate each item in the batch\n",
    "        for item in batch:\n",
    "            try:\n",
    "                translation = translator.translate(item, src='ru', dest='en').text\n",
    "                names_translated.loc[len(names_translated)] = [item, translation.capitalize()]\n",
    "            except Exception as e:\n",
    "                names_translated.loc[len(names_translated)] = [item, 'Error']\n",
    "        \n",
    "        # Pause between batches\n",
    "        time.sleep(pause_seconds)\n",
    "    \n",
    "    return names_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dept_name 196\n",
      "class_name 613\n",
      "subclass_name 1007\n",
      "item_type 674\n",
      "item_id 219810\n"
     ]
    }
   ],
   "source": [
    "# get unique values\n",
    "dept_name = catalog['dept_name'].unique()\n",
    "class_name = catalog['class_name'].unique()\n",
    "subclass_name = catalog['subclass_name'].unique()\n",
    "item_type = catalog['item_type'].unique()\n",
    "\n",
    "# Translate in batches of 100 with a 2-second pause between batches\n",
    "batch_size = 100\n",
    "pause_seconds = 2\n",
    "\n",
    "print('dept_name', len(dept_name))\n",
    "print('class_name', len(class_name))\n",
    "print('subclass_name', len(subclass_name))\n",
    "print('item_type', len(item_type))\n",
    "print('item_id', len(catalog['item_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Department name\n",
    "dept_name_translated = batch_translate(dept_name, batch_size, pause_seconds)\n",
    "\n",
    "# ! Manual substitute ! Department\n",
    "# data = dept_name_translated['name_en']\n",
    "# data[data.duplicated(keep=False)].unique()\n",
    "\n",
    "dept_name_translated[dept_name_translated['name_en'] == 'Cakes']\n",
    "dept_name_translated.iloc[10].name_en = 'Cupcakes'\n",
    "\n",
    "# 196\n",
    "len(dept_name_translated['name_en'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class name   \n",
    "class_name_translated = batch_translate(class_name, batch_size, pause_seconds)\n",
    "\n",
    "# ! Manual substitute ! Class\n",
    "data = class_name_translated['name_en']\n",
    "\n",
    "# data[data.duplicated(keep=False)].unique() # list of duplicates\n",
    "# ['Paste', 'Wheat', 'Green', 'Cottage cheese', 'Domestic', 'Salmon',\n",
    "#        'Honey', 'Black', 'Weight', 'Dumplings', 'Cakes', 'Puff', 'Bread',\n",
    "#        'Import', 'Crackers', 'Other', 'Soy sauces']\n",
    "\n",
    "class_name_translated[class_name_translated['name_en'] == 'Paste']\n",
    "class_name_translated.iloc[600].name_en = 'Pasta'\n",
    "\n",
    "class_name_translated[class_name_translated['name_en'] == 'Green']\n",
    "class_name_translated.iloc[32].name_en = 'Greens'\n",
    "\n",
    "class_name_translated[class_name_translated['name_en'] == 'Dumplings']\n",
    "class_name_translated.iloc[285].name_en = 'Varenyki'\n",
    "\n",
    "class_name_translated[class_name_translated['name_en'] == 'Cakes']\n",
    "class_name_translated.iloc[205].name_en = 'Cupcakes'\n",
    "\n",
    "# Change duplication\n",
    "len(class_name_translated['name_en'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix error translation\n",
    "error_value = class_name_translated[class_name_translated['name_en'] == 'Error']['name_ru']\n",
    "try_trans = batch_translate(error_value, batch_size, pause_seconds)\n",
    "try_trans[try_trans['name_en'] == 'Error']\n",
    "\n",
    "name_mapping = try_trans.set_index('name_ru')['name_en'].to_dict()\n",
    "\n",
    "# Replace \"Error\" with the correct values from df2, and keep the original for unmatched keys\n",
    "class_name_translated['name_en'] = class_name_translated.apply(\n",
    "    lambda row: name_mapping.get(row['name_ru'], row['name_en']) if row['name_en'] == 'Error' else row['name_en'], axis=1\n",
    ")\n",
    "\n",
    "# 599\n",
    "len(class_name_translated['name_en'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subclass name\n",
    "subclass_name_translated = batch_translate(subclass_name, batch_size, pause_seconds)\n",
    "\n",
    "# ! Manual substitute ! Subclass\n",
    "# data = subclass_name_translated['name_en']\n",
    "# data[data.duplicated(keep=False)].unique() # list of duplicates\n",
    "# ['White', 'Piece', 'Wheat', 'Red', 'Green', 'Cakes', 'Potato',\n",
    "#        'Traditional', 'Salmon', 'Weight', 'Own production', 'Jam',\n",
    "#        'Sweet', 'Corn', 'Other accessories', 'Waffle cakes', 'Plates',\n",
    "#        'Crackers', 'Breakfast', 'Cream', 'Lamps', 'Vegetables',\n",
    "#        'Croissants', 'Bread', 'Pear', 'Yeast', 'Paste', 'Other', 'Pasta',\n",
    "#        'Business lunch', 'Protein']\n",
    "\n",
    "subclass_name_translated[subclass_name_translated['name_en'] == 'Green']\n",
    "subclass_name_translated.iloc[32].name_en = 'Greens'\n",
    "\n",
    "subclass_name_translated[subclass_name_translated['name_en'] == 'Cakes']\n",
    "subclass_name_translated.iloc[124].name_en = 'Cupcakes'\n",
    "\n",
    "subclass_name_translated[subclass_name_translated['name_en'] == 'Paste']\n",
    "subclass_name_translated.iloc[432].name_en = 'Pastille'\n",
    "subclass_name_translated.iloc[791].name_en = 'Pasta'\n",
    "\n",
    "len(subclass_name_translated['name_en'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix error translation\n",
    "error_value = subclass_name_translated[subclass_name_translated['name_en'] == 'Error']['name_ru']\n",
    "try_trans = batch_translate(error_value, batch_size, pause_seconds)\n",
    "try_trans[try_trans['name_en'] == 'Error']\n",
    "\n",
    "name_mapping = try_trans.set_index('name_ru')['name_en'].to_dict()\n",
    "subclass_name_translated['name_en'] = subclass_name_translated.apply(\n",
    "    lambda row: name_mapping.get(row['name_ru'], row['name_en']) if row['name_en'] == 'Error' else row['name_en'], axis=1\n",
    ")\n",
    "\n",
    "# 975\n",
    "len(subclass_name_translated['name_en'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item type name\n",
    "item_type = pd.Series(catalog['item_type'].unique()).dropna()\n",
    "item_type_translated = batch_translate(item_type, batch_size, pause_seconds)\n",
    "\n",
    "# # ! Manual substitute ! Department\n",
    "# data = item_type_translated['name_en']\n",
    "# data[data.duplicated(keep=False)].unique()\n",
    "# ['Red', 'Green', 'Sausages', 'Coffee', 'Cottage cheese', 'Cakes',\n",
    "#        'White', 'Ham', 'Vegetables', 'Seeds', 'Rolls', 'Black',\n",
    "#        'Chocolate', 'Cream', 'Serum', 'Paste', 'Diapers', 'Jam',\n",
    "#        'National', 'Olive', 'Fresh', 'Crackers', 'Spick', 'Fruit',\n",
    "#        'Mashed potatoes', 'Mashed potatoes+side dish', 'Frozen',\n",
    "#        'Pancakes', 'Bulbs', 'Vegetable', 'Brushes', 'Egg', 'Smoked',\n",
    "#        'Blueberry', 'Radish', 'Red frozen', 'Corn', 'Cold']\n",
    "\n",
    "item_type_translated[item_type_translated['name_en'] == 'Cakes']\n",
    "item_type_translated.iloc[22].name_en = 'Cupcakes'\n",
    "\n",
    "item_type_translated[item_type_translated['name_en'] == 'Green']\n",
    "item_type_translated.iloc[3].name_en = 'Greens'\n",
    "\n",
    "item_type_translated[item_type_translated['name_en'] == 'Paste']\n",
    "item_type_translated.iloc[151].name_en = 'Pastille'\n",
    "item_type_translated.iloc[210].name_en = 'Pasta'\n",
    "# 674\n",
    "len(item_type_translated['name_en'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: name_ru, dtype: object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix error translation\n",
    "error_value = item_type_translated[item_type_translated['name_en'] == 'Error']['name_ru']\n",
    "# error_value\n",
    "try_trans = batch_translate(error_value, batch_size, pause_seconds)\n",
    "try_trans[try_trans['name_en'] == 'Error']\n",
    "\n",
    "name_mapping = try_trans.set_index('name_ru')['name_en'].to_dict()\n",
    "item_type_translated['name_en'] = item_type_translated.apply(\n",
    "    lambda row: name_mapping.get(row['name_ru'], row['name_en']) if row['name_en'] == 'Error' else row['name_en'], axis=1\n",
    ")\n",
    "\n",
    "# 635\n",
    "len(item_type_translated['name_en'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>subclass_name</th>\n",
       "      <th>item_type</th>\n",
       "      <th>weight_volume</th>\n",
       "      <th>weight_netto</th>\n",
       "      <th>fatness</th>\n",
       "      <th>dept_name_en</th>\n",
       "      <th>class_name_en</th>\n",
       "      <th>subclass_name_en</th>\n",
       "      <th>item_type_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da17e2d5feda</td>\n",
       "      <td>БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>БУМАЖНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВЛАЖНЫЕ САЛФЕТКИ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paper products</td>\n",
       "      <td>Paper products</td>\n",
       "      <td>Wet napkins</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>614de2b96018</td>\n",
       "      <td>БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВАТНЫЕ ДИСКИ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paper products</td>\n",
       "      <td>Cotton products</td>\n",
       "      <td>Cotton wheels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c1f1f3e3e11</td>\n",
       "      <td>БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВАТНАЯ ПРОДУКЦИЯ</td>\n",
       "      <td>ВАТНЫЕ ДИСКИ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paper products</td>\n",
       "      <td>Cotton products</td>\n",
       "      <td>Cotton wheels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                 dept_name          class_name  \\\n",
       "0  da17e2d5feda  БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ  БУМАЖНАЯ ПРОДУКЦИЯ   \n",
       "1  614de2b96018  БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ    ВАТНАЯ ПРОДУКЦИЯ   \n",
       "2  0c1f1f3e3e11  БУМАЖНО-ВАТНАЯ ПРОДУКЦИЯ    ВАТНАЯ ПРОДУКЦИЯ   \n",
       "\n",
       "      subclass_name item_type  weight_volume  weight_netto  fatness  \\\n",
       "0  ВЛАЖНЫЕ САЛФЕТКИ       NaN          150.0           NaN      NaN   \n",
       "1      ВАТНЫЕ ДИСКИ       NaN           30.0           NaN      NaN   \n",
       "2      ВАТНЫЕ ДИСКИ       NaN            NaN           NaN      NaN   \n",
       "\n",
       "     dept_name_en    class_name_en subclass_name_en item_type_en  \n",
       "0  Paper products   Paper products      Wet napkins          NaN  \n",
       "1  Paper products  Cotton products    Cotton wheels          NaN  \n",
       "2  Paper products  Cotton products    Cotton wheels          NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add English department name to catalog\n",
    "dept_catalog = pd.merge(catalog, dept_name_translated, left_on='dept_name', right_on='name_ru', how='left')\n",
    "dept_catalog.drop(columns=['name_ru'], inplace=True)\n",
    "dept_catalog.rename(columns={'name_en': 'dept_name_en'}, inplace=True)\n",
    "\n",
    "# Add Eng department name to catalog\n",
    "class_catalog = pd.merge(dept_catalog, class_name_translated, left_on='class_name', right_on='name_ru', how='left')\n",
    "class_catalog.drop(columns=['name_ru'], inplace=True)\n",
    "class_catalog.rename(columns={'name_en': 'class_name_en'}, inplace=True)\n",
    "\n",
    "# Add Eng subclass name to catalog\n",
    "subclass_catalog = pd.merge(class_catalog, subclass_name_translated, left_on='subclass_name', right_on='name_ru', how='left')\n",
    "subclass_catalog.drop(columns=['name_ru'], inplace=True)\n",
    "subclass_catalog.rename(columns={'name_en': 'subclass_name_en'}, inplace=True)\n",
    "\n",
    "final_catalog = pd.merge(subclass_catalog, item_type_translated, left_on='item_type', right_on='name_ru', how='left')\n",
    "final_catalog.drop(columns=['name_ru'], inplace=True)\n",
    "final_catalog.rename(columns={'name_en': 'item_type_en'}, inplace=True)\n",
    "\n",
    "dept_name_translated.to_csv('translate_products/dept_name_translated.csv')\n",
    "class_name_translated.to_csv('translate_products/class_name_translated.csv')\n",
    "subclass_name_translated.to_csv('translate_products/subclass_name_translated.csv')\n",
    "item_type_translated.to_csv('translate_products/item_type_translated.csv')\n",
    "\n",
    "final_catalog.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_catalog\n",
    "final_catalog.to_csv('final_catalog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete not used df from memory\n",
    "del dept_catalog\n",
    "del class_catalog\n",
    "del subclass_catalog\n",
    "del dept_name_translated\n",
    "del class_name_translated\n",
    "del subclass_name_translated\n",
    "del item_type_translated\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stores.csv\n",
    "Purpose: Contains stores info data.</br>\n",
    "Columns:</br>\n",
    "store_id: Store number</br>\n",
    "division: Store division</br>\n",
    "format: Store format</br>\n",
    "city: Location</br>\n",
    "area: Store sales area</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores  = pd.read_csv(root + 'stores.csv', index_col=0)\n",
    "\n",
    "# stores['name'] = stores['division'] + \" - \" + stores['format']\n",
    "# stores['location'] = stores['city'] + \" (\" + stores['area'].astype(str) + \" sqm)\"\n",
    "\n",
    "stores.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic clients, orders, managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Generate random clients\n",
    "def generate_clients(num_clients):\n",
    "    clients = []\n",
    "    for _ in range(num_clients):\n",
    "        dob = fake.date_of_birth(minimum_age=18, maximum_age=80)  # Generate date of birth between 18 and 80 years\n",
    "        age = datetime.now().year - dob.year\n",
    "        loyalty_card = str(random.randint(1000000000, 9999999999))  # 10-digit number\n",
    "        clients.append({\n",
    "            'client_id': fake.uuid4(),\n",
    "            'client_name': fake.first_name(),\n",
    "            'client_surname': fake.last_name(),\n",
    "            'client_email': fake.email(),\n",
    "            'client_phone': fake.phone_number(),\n",
    "            'client_dob': dob.strftime(\"%Y-%m-%d\"), \n",
    "            'client_age': age,\n",
    "            'client_loyalty_card': loyalty_card if random.random() > 0.17 else 0000000000  # 17% missing cards \n",
    "        })\n",
    "\n",
    "    return clients\n",
    "\n",
    "# Generate random managers\n",
    "def generate_managers(num_managers):\n",
    "    positions = ['Sales Manager', 'Store Manager', 'Regional Manager', 'Area Supervisor']\n",
    "    departments = ['Online Sales', 'Customer Service', 'Operations', 'Logistics']\n",
    "    \n",
    "    managers = []\n",
    "    for _ in range(num_managers):\n",
    "        managers.append({\n",
    "            'manager_id': fake.uuid4(),  # Unique manager ID\n",
    "            'manager_name': fake.first_name(),\n",
    "            'manager_surname': fake.last_name(),\n",
    "            'manager_position': random.choice(positions),  # Random position\n",
    "            'manager_department': random.choice(departments)  # Random department\n",
    "        })\n",
    "    return managers\n",
    "\n",
    "# Generate random orders\n",
    "def generate_orders(num_orders, managers_df):\n",
    "    orders = []\n",
    "    order_status_choices = ['Pending', 'Confirmed', 'Shipped', 'Delivered', 'Cancelled']\n",
    "    payment_methods = ['Credit Card', 'PayPal', 'Bank Transfer', 'Cash on Delivery']\n",
    "    currencies = ['USD', 'EUR']\n",
    "    packaging_choices = ['Standard', 'Gift Wrap', 'Eco-friendly', 'Custom Packaging']\n",
    "    for _ in range(num_orders):\n",
    "        manager = managers_df.sample(1).iloc[0] # random manager\n",
    "        orders.append({\n",
    "            'order_id': fake.uuid4(),  \n",
    "            'order_number': fake.ean(length=8), \n",
    "            'order_payment_type': random.choice(payment_methods),  \n",
    "            'order_status': random.choice(order_status_choices), \n",
    "            'order_currency': random.choice(currencies), \n",
    "            'order_packaging_instructions': random.choice(packaging_choices),\n",
    "            'manager_id': manager['manager_id'] \n",
    "        })\n",
    "            \n",
    "    return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = generate_clients(100_000) # 100 000 clients for 2 years\n",
    "\n",
    "# Loading the list to a file and reading it into a DataFrame works significantly faster (18.7 seconds) \n",
    "# than transforming the list directly into a DataFrame (over 22 minutes).\n",
    "json_result = json.dumps(clients, indent=4)\n",
    "with open(root + \"clients.json\", \"w\") as json_file:\n",
    "    json_file.write(json_result)\n",
    "\n",
    "print('json write')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cliends df and add Nan values\n",
    "clients_df = pd.read_json(root + \"clients.json\")\n",
    "for col in ['client_phone', 'client_email', 'client_dob', 'client_age']:\n",
    "    clients_df.loc[clients_df.sample(frac=0.3).index, col] = np.nan  # 30% of rows\n",
    "\n",
    "clients_df.to_csv(root + \"clients.csv\")\n",
    "\n",
    "clients_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers= generate_managers(100) # 100 manager for 2 years\n",
    "managers_df = pd.DataFrame(managers)\n",
    "managers_df.to_csv(root + 'managers.csv')\n",
    "managers_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = generate_orders(250_000, managers_df) # 250 000 orders in 2 years\n",
    "json_result = json.dumps(orders, indent=4)\n",
    "with open(root + \"orders.json\", \"w\") as json_file:\n",
    "     json_file.write(json_result)\n",
    "\n",
    "print('json write')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create orders df and add Nan values\n",
    "orders_df = pd.read_json(root + \"orders.json\")\n",
    "for col in ['order_payment_type', 'order_status', 'order_currency', 'order_packaging_instructions']:\n",
    "    orders_df.loc[orders_df.sample(frac=0.3).index, col] = np.nan  # 30%\n",
    "\n",
    "orders_df.to_csv(root + \"orders.csv\")\n",
    "\n",
    "orders_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sales.csv and online.csv\n",
    "Purpose: 1 This file contains aggregated store sales for specific dates. </br>\n",
    "Purpose: 2 This file contains aggregated online sales by store for specific dates.</br>\n",
    "Columns:</br>\n",
    "date: Sales date</br>\n",
    "item_id: A unique identifier for each product</br>\n",
    "quantity: Total quantity of product sold per day</br>\n",
    "price_base: Average sales price per day</br>\n",
    "sum_total: Total daily sales amount</br>\n",
    "store_id: Store number</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 7) (100000, 8) (100, 5)\n"
     ]
    }
   ],
   "source": [
    "# Create online sales file\n",
    "online_sales  = pd.read_csv(root + 'online.csv', index_col=0)\n",
    "stores  = pd.read_csv(root + 'stores.csv', index_col=0)\n",
    "discounts_history  = pd.read_csv(root + 'discounts_history.csv', index_col=0)\n",
    "\n",
    "catalog = pd.read_csv('final_catalog.csv', index_col=0)\n",
    "catalog = catalog.drop(columns=['dept_name', 'class_name' , 'subclass_name', 'item_type'])\n",
    "catalog.columns\n",
    "\n",
    "orders_df = pd.read_csv(root + 'orders.csv', index_col=0)\n",
    "clients_df = pd.read_csv(root + 'clients.csv', index_col=0)\n",
    "managers_df = pd.read_csv(root + 'managers.csv', index_col=0)\n",
    "\n",
    "print(orders_df.shape, clients_df.shape, managers_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'item_id', 'quantity', 'price_base', 'sum_total', 'store_id',\n",
       "       'order_id', 'order_number', 'order_payment_type', 'order_status',\n",
       "       'order_currency', 'order_packaging_instructions', 'manager_id',\n",
       "       'manager_name', 'manager_surname', 'manager_position',\n",
       "       'manager_department', 'client_id', 'client_name', 'client_surname',\n",
       "       'client_email', 'client_phone', 'client_dob', 'client_age',\n",
       "       'client_loyalty_card', 'weight_volume', 'weight_netto', 'fatness',\n",
       "       'dept_name_en', 'class_name_en', 'subclass_name_en', 'item_type_en',\n",
       "       'division', 'format', 'city', 'area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine everything\n",
    "\n",
    "orders_df = orders_df.merge(managers_df, on='manager_id', how='left')  # Order + manager\n",
    "online_sales['order_id'] = random.choices(orders_df['order_id'], k=len(online_sales))  # + new random column\n",
    "orders_df['client_id'] = random.choices(clients_df['client_id'], k=len(orders_df))  # + new random column\n",
    "online_sales = online_sales.merge(orders_df, on='order_id', how='left')  # sales + orders\n",
    "online_sales = online_sales.merge(clients_df, on='client_id', how='left')  # sales + client\n",
    "online_sales = online_sales.merge(catalog, on='item_id', how='left')  # sales + products\n",
    "online_sales = online_sales.merge(stores, on='store_id', how='left')  # sales + store\n",
    "\n",
    "online_sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price_base</th>\n",
       "      <th>sum_total</th>\n",
       "      <th>store_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_payment_type</th>\n",
       "      <th>order_status</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_netto</th>\n",
       "      <th>fatness</th>\n",
       "      <th>dept_name_en</th>\n",
       "      <th>class_name_en</th>\n",
       "      <th>subclass_name_en</th>\n",
       "      <th>item_type_en</th>\n",
       "      <th>division</th>\n",
       "      <th>format</th>\n",
       "      <th>city</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>4aa8dbe05246</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.40</td>\n",
       "      <td>37.20</td>\n",
       "      <td>1</td>\n",
       "      <td>fd6e0d6e-0ce2-469f-9e56-56d12305f2b8</td>\n",
       "      <td>97990154</td>\n",
       "      <td>Bank Transfer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bread</td>\n",
       "      <td>The bread is white</td>\n",
       "      <td>Own production</td>\n",
       "      <td>White</td>\n",
       "      <td>Div1</td>\n",
       "      <td>Format-1</td>\n",
       "      <td>City1</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>4e0fbcf99cf9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.27</td>\n",
       "      <td>112.54</td>\n",
       "      <td>1</td>\n",
       "      <td>ba9d9fcf-9b1c-495a-b518-a089f777ab6a</td>\n",
       "      <td>70756678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juices</td>\n",
       "      <td>For children and adults</td>\n",
       "      <td>0.9l.and more</td>\n",
       "      <td>Nectars</td>\n",
       "      <td>Div1</td>\n",
       "      <td>Format-1</td>\n",
       "      <td>City1</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>2e008b673129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.27</td>\n",
       "      <td>112.54</td>\n",
       "      <td>1</td>\n",
       "      <td>e3c27070-5c16-4d7a-89c9-ed658e4a239f</td>\n",
       "      <td>53137210</td>\n",
       "      <td>Bank Transfer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juices</td>\n",
       "      <td>For children and adults</td>\n",
       "      <td>0.9l.and more</td>\n",
       "      <td>Nectars</td>\n",
       "      <td>Div1</td>\n",
       "      <td>Format-1</td>\n",
       "      <td>City1</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       item_id  quantity  price_base  sum_total  store_id  \\\n",
       "0  2023-08-04  4aa8dbe05246       3.0       12.40      37.20         1   \n",
       "1  2023-08-04  4e0fbcf99cf9       2.0       56.27     112.54         1   \n",
       "2  2023-08-04  2e008b673129       2.0       56.27     112.54         1   \n",
       "\n",
       "                               order_id  order_number order_payment_type  \\\n",
       "0  fd6e0d6e-0ce2-469f-9e56-56d12305f2b8      97990154      Bank Transfer   \n",
       "1  ba9d9fcf-9b1c-495a-b518-a089f777ab6a      70756678                NaN   \n",
       "2  e3c27070-5c16-4d7a-89c9-ed658e4a239f      53137210      Bank Transfer   \n",
       "\n",
       "  order_status  ... weight_netto fatness dept_name_en  \\\n",
       "0          NaN  ...         0.30     NaN        Bread   \n",
       "1          NaN  ...         0.95     NaN       Juices   \n",
       "2          NaN  ...         0.95     NaN       Juices   \n",
       "\n",
       "             class_name_en subclass_name_en item_type_en division    format  \\\n",
       "0       The bread is white   Own production        White     Div1  Format-1   \n",
       "1  For children and adults    0.9l.and more      Nectars     Div1  Format-1   \n",
       "2  For children and adults    0.9l.and more      Nectars     Div1  Format-1   \n",
       "\n",
       "    city  area  \n",
       "0  City1  1500  \n",
       "1  City1  1500  \n",
       "2  City1  1500  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recalculste sales\n",
    "online_sales['sum_total'] = online_sales['price_base'] * online_sales['quantity']\n",
    "\n",
    "# change price for basic\n",
    "# online_sales['cost'] = online_sales['price_base']\n",
    "\n",
    "# result = discounts_history[['item_id', 'sale_price_before_promo']].groupby('item_id')['sale_price_before_promo'].max().reset_index()\n",
    "# result.rename(columns={'sale_price_before_promo': 'cost'}, inplace=True)\n",
    "\n",
    "# online_sales = online_sales.merge(result, on='item_id', how='left') \n",
    "\n",
    "online_sales.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_sales.to_csv('online_sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_sales.loc[:100].to_csv('online_sales_sample_100_rows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/rvz5yw3x6szdz0mdyst0tdz00000gn/T/ipykernel_1454/1479779569.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  reduced_sales = grouped.apply(lambda x: x.sample(frac=sampling_fraction, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1500018, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crop dataset from 7.1 million records to 1.5 million records\n",
    "sales  = pd.read_csv(root + 'sales.csv', index_col=0)\n",
    "\n",
    "sales['date'] = pd.to_datetime(sales['date'])\n",
    "\n",
    "# Group by date to ensure proportional sampling across all dates\n",
    "grouped = sales.groupby(sales['date'])\n",
    "\n",
    "# Target total number of records\n",
    "target_records = 1_500_000\n",
    "\n",
    "# Calculate the sampling fraction\n",
    "sampling_fraction = target_records / len(sales)\n",
    "\n",
    "# Sample from each group proportionally\n",
    "reduced_sales = grouped.apply(lambda x: x.sample(frac=sampling_fraction, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "del sales\n",
    "\n",
    "reduced_sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_sales = reduced_sales.merge(catalog, on='item_id', how='left')  # sales + products\n",
    "offline_sales = offline_sales.merge(stores, on='store_id', how='left')  # sales + store\n",
    "\n",
    "offline_sales['client_id'] = random.choices(clients_df['client_id'], k=len(offline_sales))  # + new random column\n",
    "num_nan = int(len(offline_sales) * 0.7)  # Calculate the number of NaN rows, 70%\n",
    "# Randomly select rows to assign NaN to client_id\n",
    "nan_indices = random.sample(range(len(offline_sales)), num_nan)\n",
    "offline_sales.loc[nan_indices, 'client_id'] = np.nan\n",
    "\n",
    "offline_sales = offline_sales.merge(clients_df, on='client_id', how='left')  # sales + client\n",
    "\n",
    "offline_sales['sum_total'] = offline_sales['price_base'] * offline_sales['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_sales.to_csv('offline_sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_sales.loc[:100].to_csv('offline_sales_sample_100_rows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_history  = pd.read_csv(root + 'price_history.csv', index_col=0)\n",
    "actual_matrix  = pd.read_csv(root + 'actual_matrix.csv', index_col=0)\n",
    "discounts_history  = pd.read_csv(root + 'discounts_history.csv', index_col=0)\n",
    "markdowns  = pd.read_csv(root + 'markdowns.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## markdowns.csv\n",
    "Purpose: This file provides data on products sold at markdown prices in each store. </br>\n",
    "Columns:</br>\n",
    "date: Date of markdown</br>\n",
    "item_id: A unique identifier for each product</br>\n",
    "normal_price: Regular price</br>\n",
    "price: Price during markdown</br>\n",
    "quantity: Quantity sold at markdown</br>\n",
    "store_id: Store number</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdowns.head(3) # уцінка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## price_history.csv\n",
    "Purpose: This file contains price changes data in each store.</br>\n",
    "Columns:</br>\n",
    "date: Date of price change</br>\n",
    "item_id: A unique identifier for each product</br>\n",
    "price: Item new price</br>\n",
    "code: Price change code</br>\n",
    "store_id: Store number</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_history.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## actual_matrix.csv\n",
    "Purpose: Contains the list of products available in stores.</br>\n",
    "Columns:</br>\n",
    "item_id: A unique identifier for each product</br>\n",
    "date: Date of last product appearance in the current matrix</br>\n",
    "store_id: Store number</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_matrix.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discounts_history.csv\n",
    "Purpose: Contains historical promo data for each specific store.</br>\n",
    "Columns:</br>\n",
    "date: Date</br>\n",
    "item_id: A unique identifier for each product</br>\n",
    "sale_price_before_promo: Price before promo period started</br>\n",
    "sale_price_time_promo: Price during the promo period</br>\n",
    "promo_type_code: Promo code type</br>\n",
    "doc_id: Promo document number</br>\n",
    "number_disc_day: Sequential day number of the current promo period</br>\n",
    "store_id: Store number</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discounts_history.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
